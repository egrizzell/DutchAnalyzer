{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "from psycopg import sql, Connection\n",
    "from psycopg.types.json import set_json_dumps, set_json_loads, Json\n",
    "\n",
    "import os\n",
    "from dutchanalyzer.config import *\n",
    "from dutchanalyzer.utilities.utils import *\n",
    "from dutchanalyzer.utilities.json_utils import *\n",
    "from dutchanalyzer.utilities.database_utils import *\n",
    "from pathlib import Path\n",
    "import ujson\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80b3d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dutchanalyzer.utilities.util_vars import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19e15422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3976dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with psycopg.connect(f\"dbname={os.getenv('cleaning_database')} user={os.getenv('database_username')} password={os.getenv('database_password')} host={os.getenv('database_host')} port={os.getenv('database_port')}\") as conn:\n",
    "\n",
    "#     # Open a cursor to perform database operations\n",
    "#     with conn.cursor() as cur:\n",
    "\n",
    "#         # Execute a command: this creates a new table\n",
    "#         if cur:\n",
    "            \n",
    "#             \n",
    "#             # 27\n",
    "#             cur.execute(\"\"\"\n",
    "#             CREATE TABLE IF NOT EXISTS wiktionary_entries (\n",
    "#                 id bigserial PRIMARY KEY,\n",
    "#                 word TEXT,\n",
    "#                 pos TEXT REFERENCES primary_parts_of_speech(pos_code), \n",
    "#                 lang_code TEXT REFERENCES languages(lang_code),\n",
    "#                 def_lang_code TEXT REFERENCES languages(lang_code),\n",
    "#                 f_code TEXT, \n",
    "#                 processing_complete BOOL DEFAULT False,\n",
    "#                 original_json JSONB, \n",
    "#                 added_on TIMESTAMPTZ,\n",
    "#                 updated_at TIMESTAMPTZ\n",
    "#                     )\n",
    "#                 \"\"\")\n",
    "#             #41\n",
    "#             cur.execute( \n",
    "#                 \"\"\" \n",
    "#                 CREATE TABLE IF NOT EXISTS processing_statuses (\n",
    "#                 id bigserial PRIMARY KEY,\n",
    "#                 raw_id BIGINT REFERENCES wiktionary_entries(id),\n",
    "#                 further_processing_status BOOL DEFAULT False,\n",
    "#                 synonyms_status BOOL DEFAULT False,\n",
    "#                 antoyms_status BOOL DEFAULT False,\n",
    "#                 translations_status BOOL DEFAULT False,\n",
    "#                 etymology_status BOOL DEFAULT False,\n",
    "#                 links_status BOOL DEFAULT False,\n",
    "#                 topics_status BOOL DEFAULT False,\n",
    "#                 derived_status BOOL DEFAULT False,\n",
    "#                 alt_status BOOL DEFAULT False,\n",
    "#                 forms_status BOOL DEFAULT False,\n",
    "#                 sounds_status BOOL DEFAULT False, \n",
    "#                 hyphenations_status BOOL DEFAULT False,\n",
    "#                 inflection_templates_status BOOL DEFAULT False,\n",
    "#                 categories_status BOOL DEFAULT False,\n",
    "#                 hypernyms_status BOOL DEFAULT False,\n",
    "#                 hyponyms_status BOOL DEFAULT False,\n",
    "#                 meronyms_status BOOL DEFAULT False,\n",
    "#                 toponyms_status BOOL DEFAULT False,\n",
    "#                 related_status BOOL DEFAULT False,\n",
    "#                 sense_status BOOL DEFAULT False,\n",
    "#                 gloss_status BOOL DEFAULT False,\n",
    "#                 short_gloss_status BOOL DEFAULT False, \n",
    "#                 sense_translations BOOL DEFAULT False, \n",
    "#                 sense_forms BOOL DEFAULT False, \n",
    "#                 sense_tags BOOL DEFAULT False, \n",
    "#                 sense_categories BOOL DEFAULT False, \n",
    "#                 sense_alt BOOL DEFAULT False, \n",
    "#                 sense_topics BOOL DEFAULT False, \n",
    "#                 sense_nym_status BOOL DEFAULT False \n",
    "#                 )\n",
    "#                 \"\"\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4f779bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_primary_parts_of_speech_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1c731c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_exists('primary_parts_of_speech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66d934d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_languages_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3c44b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_exists('languages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01dfcb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_public_table('entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ee0a1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with psycopg.connect(f\"dbname={os.getenv('cleaning_database')} user={os.getenv('database_username')} password={os.getenv('database_password')} host={os.getenv('database_host')} port={os.getenv('database_port')}\") as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                if cur:\n",
    "                        pos_code = \"affix\"\n",
    "                        \n",
    "                        nl_name = \"toevoegsel\"\n",
    "                        nl_abbr = \"add\"\n",
    "                        en_name = \"affix\"\n",
    "    \n",
    "                        cur.execute(t\"INSERT INTO primary_parts_of_speech (pos_code, en_name, nl_name, nl_abbr) VALUES ({pos_code}, {en_name}, {nl_name}, {nl_abbr})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e572e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe6c1e",
   "metadata": {},
   "source": [
    "### Future Full Table Schema\n",
    "wiktionary_entries (  \n",
    "    id bigserial PRIMARY KEY, <br>\n",
    "    word TEXT, <br>\n",
    "    pos TEXT REFERENCES primary_parts_of_speech(pos_code), <br>\n",
    "    lang_code TEXT REFERENCES languages(lang_code), <br>\n",
    "    def_lang_code TEXT REFERENCES languages(lang_code), <br>\n",
    "    f_code TEXT, <br>\n",
    "    processing_complete BOOL DEFAULT False, <br>\n",
    "    original_json JSONB, <br>\n",
    "    dump_date DATE, <br>\n",
    "    added_on TIMESTAMPTZ, <br>\n",
    "    updated_at TIMESTAMPTZ <br>\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36e7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_raw_rows_batch(file, start_at=0, batch_size=100000):\n",
    "    batch = {}\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        for i, line in tqdm(enumerate(f), desc= f'adding entries from {file.stem}'):\n",
    "            if i < start_at:\n",
    "                continue\n",
    "            if line:\n",
    "                obj = json.loads(line)\n",
    "                if obj:\n",
    "                    f_code, word, pos = get_eid_word_pos(obj)\n",
    "                    lang_code = obj.get('lang_code')\n",
    "                    \n",
    "                    if f_code.startswith('E'):\n",
    "                        def_lang_code = 'en'\n",
    "                    else:\n",
    "                        def_lang_code = 'nl'\n",
    "                    batch.append({'word':word, 'pos':pos, 'lang_code':lang_code, 'def_lang_code':def_lang_code, 'f_code':f_code, 'original_json':obj})\n",
    "                    if len(batch) > batch_size:\n",
    "                        return batch, i, False\n",
    "        return batch, i, True\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b4e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ff85b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df819328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_raw_entry(cur, obj: dict):\n",
    "    query = \"\"\"\n",
    "        INSERT INTO wiktionary_entries (\n",
    "            word,\n",
    "            pos,\n",
    "            lang_code,\n",
    "            def_lang_code,\n",
    "            f_code,\n",
    "            processing_complete,\n",
    "            original_json,\n",
    "            dump_date,\n",
    "            added_on,\n",
    "            updated_at\n",
    "        )\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "    dump_date = date(2025, 1, 10)  \n",
    "    f_code, word, pos = get_eid_word_pos(obj)\n",
    "    lang_code = obj.get('lang_code')\n",
    "    \n",
    "    if f_code.startswith('E'):\n",
    "        def_lang_code = 'en'\n",
    "    else:\n",
    "        def_lang_code = 'nl'\n",
    "    \n",
    "    cur.execute(\n",
    "        query,\n",
    "        (\n",
    "            word,\n",
    "            pos,\n",
    "            lang_code,\n",
    "            def_lang_code,\n",
    "            f_code,\n",
    "            bool(obj.get(\"processing_complete\", False)),  \n",
    "            Json(obj),                                    \n",
    "            dump_date,\n",
    "            datetime.now(),\n",
    "            datetime.now()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac9b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wiktionary_entries_table(db='cleaning_db'):\n",
    "    if db == 'cleaning_db':\n",
    "        with psycopg.connect(f\"dbname={os.getenv('cleaning_database')} user={os.getenv('database_username')} password={os.getenv('database_password')} host={os.getenv('database_host')} port={os.getenv('database_port')}\") as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                if cur:\n",
    "                    cur.execute(\"\"\" CREATE TABLE IF NOT EXISTS wiktionary_entries ( \n",
    "                                 id bigserial PRIMARY KEY, \n",
    "                                word TEXT, \n",
    "                                pos TEXT REFERENCES primary_parts_of_speech(pos_code), \n",
    "                                lang_code TEXT REFERENCES languages(lang_code), \n",
    "                                def_lang_code TEXT REFERENCES languages(lang_code), \n",
    "                                f_code TEXT, \n",
    "                                processing_complete BOOL DEFAULT False, \n",
    "                                original_json JSONB, \n",
    "                                dump_date DATE, \n",
    "                                added_on TIMESTAMPTZ, \n",
    "                                updated_at TIMESTAMPTZ \n",
    "                                    )\n",
    "                                \"\"\")      \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_wiktionary_entries_table(file: Path, db='cleaning_db', start_index=0):\n",
    "    error_lines = []\n",
    "    if db == 'cleaning_db':\n",
    "        with psycopg.connect(f\"dbname={os.getenv('cleaning_database')} user={os.getenv('database_username')} password={os.getenv('database_password')} host={os.getenv('database_host')} port={os.getenv('database_port')}\") as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                if cur:\n",
    "                    with open(file, 'r', encoding='utf-8') as f:\n",
    "                        for i, line in tqdm(enumerate(f), desc= f'adding entries from {file.stem}', total=count_lines_with_progress(file, quiet=True)):\n",
    "                            if i >= start_index:\n",
    "                                if line:\n",
    "                                    try:\n",
    "                                        obj = json.loads(line)\n",
    "                                        if obj:\n",
    "                                            insert_raw_entry(cur, obj)\n",
    "                                    except Exception as e:\n",
    "                                        error_lines.append((i, e, obj))\n",
    "    return error_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b860d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_wiktionary_entries_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1cdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_exists('wiktionary_entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c917b4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding entries from ENF: 100%|██████████| 127859/127859 [00:29<00:00, 4291.88it/s]\n"
     ]
    }
   ],
   "source": [
    "fill_wiktionary_entries_table(ENF_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f8274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding entries from EEF: 100%|██████████| 1230354/1230354 [00:02<00:00, 417961.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_wiktionary_entries_table(EEF_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91c2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding entries from NEF: 100%|██████████| 16331/16331 [00:03<00:00, 5356.37it/s]\n"
     ]
    }
   ],
   "source": [
    "fill_wiktionary_entries_table(NEF_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcfcaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding entries from NNF: 100%|██████████| 598925/598925 [01:50<00:00, 5397.21it/s]\n"
     ]
    }
   ],
   "source": [
    "fill_wiktionary_entries_table(NNF_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c65c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding entries from NOF: 100%|██████████| 4368/4368 [00:00<00:00, 7133.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding entries from EOF: 100%|██████████| 46278/46278 [00:08<00:00, 5736.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_wiktionary_entries_table(NOF_FILE)\n",
    "fill_wiktionary_entries_table(EOF_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc62eb08",
   "metadata": {},
   "source": [
    "## Check Table Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1266b4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190552\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "with psycopg.connect(f\"dbname={os.getenv('cleaning_database')} user={os.getenv('database_username')} password={os.getenv('database_password')} host={os.getenv('database_host')} port={os.getenv('database_port')}\") as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        if cur:\n",
    "            verbs = cur.execute(\"SELECT * FROM wiktionary_entries WHERE pos='verb'\").fetchall()\n",
    "            print(len(verbs))\n",
    "            print(type(verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6bcbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entries_where(table, cols='*', clause='WHERE', condition='lang_code', filter_value='en', fetch_type='all'):\n",
    "    with psycopg.connect(f\"dbname={os.getenv('cleaning_database')} user={os.getenv('database_username')} password={os.getenv('database_password')} host={os.getenv('database_host')} port={os.getenv('database_port')}\") as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            if cur:\n",
    "                if not is_public_table(table):\n",
    "                    return []\n",
    "                \n",
    "                query = \"SELECT {} FROM {} WHERE {}= '{}'\".format(cols, table, condition, filter_value)\n",
    "                result = cur.execute(query)\n",
    "                if fetch_type == 'all':\n",
    "                    return result.fetchall()\n",
    "                elif fetch_type == 'one':\n",
    "                    return result.fetchone()\n",
    "                elif fetch_type == 'result':\n",
    "                    return result\n",
    "                else:\n",
    "                    print('not implemented')\n",
    "\n",
    "                return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6478e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<psycopg.Cursor [TUPLES_OK] [INTRANS] (host=127.0.0.1 user=postgres database=cleaning_db) at 0x21fe719ab10>\n"
     ]
    }
   ],
   "source": [
    "entries = get_entries_where('wiktionary_entries', condition='pos', filter_value='verb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "24875b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190552"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5103bec",
   "metadata": {},
   "source": [
    "## Cleaning Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f5ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_into_cols(conn, entry):\n",
    "    query = \"\"\" SELECT \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d5a574eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_processing_queue():\n",
    "    with psycopg.connect(f\"dbname={os.getenv('cleaning_database')} user={os.getenv('database_username')} password={os.getenv('database_password')} host={os.getenv('database_host')} port={os.getenv('database_port')}\") as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            if cur:\n",
    "                cols_not_to_add = ['entry_id', 'word', 'pos', 'lang', 'lang_code', 'wl_code']\n",
    "                \n",
    "                cur.execute(\"\"\" CREATE TABLE IF NOT EXISTS processing_queue AS \n",
    "                            SELECT \n",
    "                            id                          as wikt_id,\n",
    "                            COALESCE(original_json->>'entry_id', '')          AS eid,\n",
    "                            COALESCE(original_json->>'word', 'UNKNOWN')              AS word,\n",
    "                            COALESCE(original_json->>'pos', 'unk')               AS pos,\n",
    "                            COALESCE(original_json->>'wl_code', 'UNK')           AS wl_code,\n",
    "                            original_json                       AS original_json,\n",
    "                            NOW()                             AS created_at\n",
    "                        FROM wiktionary_entries\n",
    "                        WHERE processing_complete = FALSE\n",
    "                            \n",
    "                    \"\"\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "94a781fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_processing_queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db811745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c553a463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<psycopg.Cursor [TUPLES_OK] [INTRANS] (host=127.0.0.1 user=postgres database=cleaning_db) at 0x21fe7598410>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entries_where('processing_queue', condition='wl_code', filter_value='ENF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a9bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search_users(\n",
    "#     conn: Connection,\n",
    "#     ids: Sequence[int] | None = None,\n",
    "#     name_pattern: str | None = None,\n",
    "#     group_id: int | None = None,\n",
    "#     ) -> list[User]:\n",
    "#         filters = []\n",
    "#         if ids is not None:\n",
    "#             ids = list(ids)\n",
    "#             filters.append(t\"u.id = ANY({ids})\")\n",
    "#         if name_pattern is not None:\n",
    "#             filters.append(t\"u.name ~* {name_pattern}\")\n",
    "#         if group_id is not None:\n",
    "#             filters.append(t\"u.group_id = {group_id}\")\n",
    "#         if not filters:\n",
    "#             raise TypeError(\"please specify at least one search parameter\")\n",
    "\n",
    "#         joined = sql.SQL(\" AND \").join(filters)\n",
    "#         cur = conn.cursor(row_factory=class_row(User))\n",
    "#         cur.execute(t\"SELECT * FROM users AS u WHERE {joined:q}\")\n",
    "#     return cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef0f038",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f4973a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_col_schemas_in_db(db='cleaning_db'):\n",
    "   if db == 'cleaning_db':\n",
    "        with psycopg.connect(f\"dbname={os.getenv('cleaning_database')} user={os.getenv('database_username')} password={os.getenv('database_password')} host={os.getenv('database_host')} port={os.getenv('database_port')}\") as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                if cur:\n",
    "                    db_schema = {}\n",
    "\n",
    "                    rows = cur.execute(\"\"\"\n",
    "                        SELECT \n",
    "                            table_schema,\n",
    "                            table_name,\n",
    "                            column_name,\n",
    "                            data_type\n",
    "                        FROM information_schema.columns\n",
    "                        WHERE table_schema = 'public'\n",
    "                        ORDER BY table_schema, table_name, ordinal_position;\n",
    "                        \"\"\")\n",
    "              \n",
    "                    for schema, table, column, dtype in rows:\n",
    "                        if table not in db_schema:\n",
    "                            db_schema[table] = {column:dtype}\n",
    "                        else:\n",
    "                            db_schema[table][column] = dtype\n",
    "        \n",
    "                    return db_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "abc65cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'languages': {'lang_code': 'text',\n",
       "  'lang': 'text',\n",
       "  'dutch_name': 'text',\n",
       "  'english_name': 'text'},\n",
       " 'primary_parts_of_speech': {'pos_code': 'text',\n",
       "  'dutch_name': 'text',\n",
       "  'dutch_abbr': 'text',\n",
       "  'english_name': 'text'},\n",
       " 'processing_statuses': {'id': 'bigint',\n",
       "  'raw_id': 'bigint',\n",
       "  'further_processing_status': 'boolean',\n",
       "  'synonyms_status': 'boolean',\n",
       "  'antoyms_status': 'boolean',\n",
       "  'translations_status': 'boolean',\n",
       "  'etymology_status': 'boolean',\n",
       "  'links_status': 'boolean',\n",
       "  'topics_status': 'boolean',\n",
       "  'derived_status': 'boolean',\n",
       "  'alt_status': 'boolean',\n",
       "  'forms_status': 'boolean',\n",
       "  'sounds_status': 'boolean',\n",
       "  'hyphenations_status': 'boolean',\n",
       "  'inflection_templates_status': 'boolean',\n",
       "  'categories_status': 'boolean',\n",
       "  'hypernyms': 'boolean',\n",
       "  'hyponyms': 'boolean',\n",
       "  'meronyms': 'boolean',\n",
       "  'toponyms': 'boolean',\n",
       "  'related': 'boolean',\n",
       "  'sense_status': 'boolean',\n",
       "  'gloss_status': 'boolean',\n",
       "  'short_gloss_status': 'boolean',\n",
       "  'sense_translations': 'boolean',\n",
       "  'sense_forms': 'boolean',\n",
       "  'sense_tags': 'boolean',\n",
       "  'sense_categories': 'boolean',\n",
       "  'sense_alt': 'boolean',\n",
       "  'sense_topics': 'boolean',\n",
       "  'sense_nym_status': 'boolean'},\n",
       " 'raw_entries': {'id': 'bigint',\n",
       "  'word': 'text',\n",
       "  'pos': 'text',\n",
       "  'lang_code': 'text',\n",
       "  'def_lang_code': 'text',\n",
       "  'f_code': 'text',\n",
       "  'processing_complete': 'boolean',\n",
       "  'original_json': 'jsonb',\n",
       "  'added_on': 'timestamp with time zone',\n",
       "  'updated_at': 'timestamp with time zone'}}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_table_col_schemas_in_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5666e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
