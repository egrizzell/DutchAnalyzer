{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "9d75d49b",
            "metadata": {},
            "source": [
                "# Extracting one word definitions from the ENF file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "f48668ab",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "from pathlib import Path\n",
                "from dutchanalyzer.config import *\n",
                "from dutchanalyzer.utilities.utils import *\n",
                "from dutchanalyzer.utilities.json_utils import *\n",
                "from dutchanalyzer.utilities.replacement_utils import *\n",
                "from dutchanalyzer.utilities.pandas_utils import *\n",
                "import datetime\n",
                "from tqdm import tqdm\n",
                "import pickle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "10fe13aa",
            "metadata": {},
            "outputs": [],
            "source": [
                "today = datetime.date.today().__format__(\"%d-%m-%y\")\n",
                "current_save_folder = Path(WIKT_CLEANING_DIR, str(today))\n",
                "folders = ['EEF', 'ENF', 'NNF', 'NEF']\n",
                "\n",
                "\n",
                "for f in folders:\n",
                "    ",
                "        Path.mkdir(Path(current_save_folder, f), parents=True, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8d5919b4",
            "metadata": {},
            "source": [
                "## Add entry ids"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "379753b7",
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_temp_file_path(file):\n",
                "    \n",
                "    if not isinstance(file, Path):\n",
                "        file = Path(file)\n",
                "    temp_name = f'{file.stem}_temp.jsonl'\n",
                "    folder = file.parents[0]\n",
                "    temp_file = Path(folder, temp_name)\n",
                "    return temp_file\n",
                "      "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5af928fa",
            "metadata": {},
            "outputs": [],
            "source": [
                "def add_entry_ids(file, overwrite=False):\n",
                "    batch = []\n",
                "    batch_size = 100000\n",
                "    wl_code = get_file_wl_code(file)\n",
                "    temp_file = make_temp_file_path(file)\n",
                "    with open(file, 'r', encoding='utf-8') as f:\n",
                "        with open(temp_file, 'w+',encoding='utf-8') as out:\n",
                "            for i, line in tqdm(enumerate(f)):\n",
                "                if line:\n",
                "                    loaded = json.loads(line)\n",
                "                    if loaded:\n",
                "                        if 'entry_id' not in loaded:\n",
                "                            loaded['entry_id'] = f'{wl_code}_{i}'\n",
                "                            sorted_keys = sort_entry_keys(loaded, start_keys=['entry_id', 'word', 'pos', 'lang_code', 'lang', 'senses'])\n",
                "                            obj = {}\n",
                "                            for k in sorted_keys:\n",
                "                                obj[k] = loaded[k]\n",
                "                        batch.append(obj)\n",
                "                    \n",
                "                if len(batch) > batch_size:\n",
                "                    for b in batch:\n",
                "                        json.dump(b, out, ensure_ascii=False)\n",
                "                        out.write('\\n')\n",
                "                    batch = []\n",
                "            if batch:\n",
                "                for b in batch:\n",
                "                    json.dump(b, out, ensure_ascii=False)\n",
                "                    out.write('\\n')\n",
                "    if overwrite:\n",
                "        overwrite_file(file, temp_file)\n",
                "    return batch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8a8f36af",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "1230364it [01:50, 11181.49it/s]\n"
                    ]
                }
            ],
            "source": [
                "batch = add_entry_ids(EEF_FILE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5d1a173e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "127859it [00:15, 8508.89it/s] \n"
                    ]
                }
            ],
            "source": [
                "batch = add_entry_ids(ENF_FILE)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "id": "500c74ae",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "598925it [00:54, 10920.22it/s]\n"
                    ]
                }
            ],
            "source": [
                "batch = add_entry_ids(NNF_FILE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "id": "de4ae09f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "16343it [00:00, 23340.38it/s]\n"
                    ]
                }
            ],
            "source": [
                "batch = add_entry_ids(NEF_FILE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "id": "c6d1bd4a",
            "metadata": {},
            "outputs": [],
            "source": [
                "overwrite_file(EEF_FILE, Path(EEF_FOLDER, 'EEF_temp.jsonl'), quiet=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "id": "4c16e945",
            "metadata": {},
            "outputs": [],
            "source": [
                "overwrite_file(ENF_FILE, Path(ENF_FOLDER, 'ENF_temp.jsonl'), quiet=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "id": "51679ab5",
            "metadata": {},
            "outputs": [],
            "source": [
                "overwrite_file(NNF_FILE, Path(NNF_FOLDER, 'NNF_temp.jsonl'), quiet=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "id": "9126ab38",
            "metadata": {},
            "outputs": [],
            "source": [
                "overwrite_file(NEF_FILE, Path(NEF_FOLDER, 'NEF_temp.jsonl'), quiet=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eda07edb",
            "metadata": {},
            "source": [
                "## Get entry counts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bcf88e2b",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_entry_counts(file, wl_code, with_pos=True, quiet=False):\n",
                "    entry_count = {}\n",
                "    entry_id = 0\n",
                "    total_lines = count_lines_with_progress(file)\n",
                "    with open(file, 'r', encoding='utf-8') as f:\n",
                "       \n",
                "        for i, line in tqdm(enumerate(f), total=total_lines, desc='getting entry counts'):\n",
                "            obj = json.loads(line)\n",
                "            if obj:\n",
                "                word = obj.get('word', '')\n",
                "                pos = obj.get('pos', '')\n",
                "                id = obj.get('entry_id')\n",
                "                if not id:\n",
                "                    id = f'{wl_code}_{entry_id}'\n",
                "                    entry_id += 1\n",
                "                item = word\n",
                "                if with_pos:\n",
                "                    item = (word, pos)\n",
                "                if word not in entry_count:\n",
                "                    entry_count[item] = {'count': 1}\n",
                "                    entry_count[item]['entry_ids'] = [id]\n",
                "                else:\n",
                "                    entry_count[item]['count'] += 1\n",
                "                    entry_count[item]['entry_ids'].append(id)\n",
                "    return entry_count"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "id": "37e3a597",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Counting Lines:   0%|          | 0.00/162M [00:00<?, ?B/s]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Counting Lines: 100%|██████████| 162M/162M [00:00<00:00, 1.29GB/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Lines in file: 127859\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "getting entry counts: 100%|██████████| 127859/127859 [00:01<00:00, 65380.42it/s]\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "125576"
                        ]
                    },
                    "execution_count": 43,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "entries = get_entry_counts(ENF_FILE, 'ENF')\n",
                "one_entry_words = [x for x in entries.keys() if entries[x]['count'] == 1]\n",
                "len(one_entry_words)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "id": "43d08228",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_one_sense_entries(file, one_entry_words=[], wl_code='', one_sense_entries_file='', one_gloss_file=''):\n",
                "    one_sense_entries = []\n",
                "    one_gloss_entries = []\n",
                "    if not one_entry_words:\n",
                "        if not wl_code:\n",
                "            wl_code = get_file_wl_code(file)\n",
                "        entry_count = get_entry_counts(file, wl_code)\n",
                "        one_entry_words = [x for x in entries.keys() if entries[x]['count'] == 1]\n",
                "    with open(file, 'r', encoding='utf-8') as f:\n",
                "        for i, line in tqdm(enumerate(f), 'narrowing senses and glosses'):\n",
                "\n",
                "            obj = json.loads(line)\n",
                "            if obj:\n",
                "                word = obj.get('word', '')\n",
                "                pos = obj.get('pos', '')\n",
                "                item = (word, pos)\n",
                "                if item in one_entry_words:\n",
                "                    entry_id = obj.get('entry_id')\n",
                "                    senses = obj.get('senses', '')\n",
                "                    if senses and len(senses) == 1:\n",
                "                        one_sense_entries.append(obj)\n",
                "                        glosses = senses[0].get('glosses')\n",
                "                        if glosses and len(glosses) == 1:\n",
                "                            one_gloss_entries.append({'entry_id': entry_id, 'word': word, 'pos': pos,'gloss': glosses[0]})\n",
                "    \n",
                "    if one_sense_entries_file:\n",
                "        with open(one_sense_entries_file, 'w+', encoding='utf-8') as f:\n",
                "            for obj in one_sense_entries:\n",
                "                json.dump(obj, f, ensure_ascii=False)\n",
                "                f.write('\\n')\n",
                "                \n",
                "    if one_gloss_file:\n",
                "        with open(one_gloss_file, 'w+', encoding='utf-8') as f:\n",
                "            for obj in one_gloss_entries:\n",
                "                json.dump(obj, f, ensure_ascii=False)\n",
                "                f.write('\\n')\n",
                "\n",
                "    return one_sense_entries, one_gloss_entries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "id": "6f18020b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "narrowing senses and glosses: 127859it [05:21, 398.03it/s]\n"
                    ]
                }
            ],
            "source": [
                "file = ENF_FILE\n",
                "wl_code = 'ENF'\n",
                "one_sense_entries, one_gloss_one_sense_entries = get_one_sense_entries(ENF_FILE, one_entry_words, wl_code, one_sense_entries_file=Path(current_save_folder, 'en', 'ENF','ENF_one_sense_entries.jsonl'), one_gloss_file=Path(current_save_folder, 'en', 'ENF', 'ENF_one_gloss_entries.jsonl'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "id": "250b98e8",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "98431"
                        ]
                    },
                    "execution_count": 58,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "len(one_gloss_one_sense_entries)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "927559f1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# if an entry is 2 words this will also accept 2 word definition\n",
                "def get_3_or_less_word_defs(entries):\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4c58456e",
            "metadata": {},
            "outputs": [],
            "source": [
                "get_3_or_less_word_defs(one_gloss_one_sense_entries)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}